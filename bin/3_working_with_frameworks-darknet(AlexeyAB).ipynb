{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Set\n"
     ]
    }
   ],
   "source": [
    "IMAGE_LABEL_DIR = '../data/processed_data/images_labelled/'\n",
    "\n",
    "DARKNET_DOWNLOAD_DIR = '../Frameworks/'\n",
    "\n",
    "## Config in Darknet to use\n",
    "CONFIG_TO_USE_FILE_PATH = '../config/darknet_cfgs_convs_weights/downloaded/YOLOv3-608.cfg'\n",
    "WEIGHTS_TO_LOAD_FILE_PATH = '../config/darknet_cfgs_convs_weights/downloaded/YOLOv3-608.weights'\n",
    "THRESHOLD_TO_USE = 0.25\n",
    "## \n",
    "TEST_IMAGE_PATH = '../data/processed_data/images_labelled/172_0_2834.jpeg' \n",
    "# data/dog.jpg'\n",
    "\n",
    "\n",
    "## Required Training Files \n",
    "DOT_DATA_FILE_PATH = '../data/processed_data/nuggets.data'\n",
    "DOT_NAMES_FILE_PATH = '../data/processed_data/nuggets.names' \n",
    "TRAIN_IMAGES_PATH_FILE_PATH = '../data/processed_data/train.txt'\n",
    "TEST_IMAGES_PATH_FILE_PATH = '../data/processed_data/test.txt'\n",
    "BACKUP_DIR = '../model_backup/'\n",
    "TRAIN_SIZE = 0.8\n",
    "CONVOLUTION_LAYER_FILE_PATH = '../config/darknet_cfgs_convs_weights/downloaded/darknet53.conv.74'\n",
    "\n",
    "## TRAINING REQUIREMENT\n",
    "'''\n",
    "    - CONFIG_TO_USE_FILE_PATH\n",
    "    - CONVOLUTION_LAYER_FILE_PATH\n",
    "    - TRAIN_SIZE\n",
    "    - DOT_DATA_FILE_PATH\n",
    "    - \n",
    "    - \n",
    "'''\n",
    "## TESTING REQUIREMENT\n",
    "'''\n",
    "    - CONFIG_TO_USE_FILE_PATH\n",
    "    - DOT_DATA_FILE_PATH\n",
    "    - \n",
    "    - WEIGHTS_TO_LOAD_FILE_PATH\n",
    "    - THRESHOLD_TO_USE\n",
    "\n",
    "'''\n",
    "print('Value Set')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Weights & Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmd.add('Download - yolo v3 weights', '!wget https://pjreddie.com/media/files/yolov3.weights')\n",
    "# cmd.add('Download - yolo v3 conv', '!wget https://pjreddie.com/media/files/darknet53.conv.74')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## '.data', '.names', 'train.txt', & 'test.txt' file creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_img_lab_files_paths(config_dict):\n",
    "    '''\n",
    "    get the image and label files that are present in the provided directory\n",
    "    '''\n",
    "    training_data_dir = config_dict['paths']['input']['training_data_dir']\n",
    "    files = glob.glob(training_data_dir+'*')\n",
    "    img_files_path = [ e for e in files if e.split('.')[-1].lower() in ['jpg', 'jpeg', 'png'] ]\n",
    "    lab_files_path = [ e for e in files if e.split('.')[-1].lower() in ['txt'] ]\n",
    "    \n",
    "    ## Converting JPEG to jpg\n",
    "    ## Renaming\n",
    "    [ os.rename(pt, pt.replace('.jpeg','.jpg')) for pt in img_files_path if os.path.exists(pt.replace('.jpeg','.jpg')) is False ]\n",
    "    [ os.rename(pt, pt.replace('.JPEG','.jpg')) for pt in img_files_path if os.path.exists(pt.replace('.jpeg','.jpg')) is False ]\n",
    "    \n",
    "    return img_files_path, lab_files_path\n",
    "\n",
    "\n",
    "def write_txt_having_paths_to_train_test_images(config_dict):\n",
    "    '''\n",
    "    Writing the training and test txt files contatining the paths to the images\n",
    "    '''\n",
    "    train_txt_path = config_dict['paths']['output']['txt_having_paths_to_train_images']\n",
    "    test_txt_path = config_dict['paths']['output']['txt_having_paths_to_test_images']\n",
    "    train_size = float(config_dict['train_size'])\n",
    "    image_files_path, _ = get_img_lab_files_paths(config_dict)\n",
    "    image_files_path = [ os.path.abspath(e) for e in image_files_path ]\n",
    "    train_li, test_li = train_test_split(image_files_path, train_size= train_size, shuffle=True)\n",
    "    \n",
    "    for path, content in [(train_txt_path, train_li), (test_txt_path, test_li)]:\n",
    "        with open(path, 'w+') as file:\n",
    "            file.write('\\n'.join(content))\n",
    "            print('[File Written] \"{}\" has been written at :\\n\\t{}'.format(\n",
    "                path.split('/')[-1], path))    \n",
    "    \n",
    "\n",
    "def write_data_and_names_files(config_dict):\n",
    "    ''' \n",
    "     create this file:\n",
    "                      .data\n",
    "                      .names      \n",
    "    '''\n",
    "    training_data_dir = config_dict['paths']['input']['training_data_dir']\n",
    "    name_file_path = config_dict['paths']['output']['.name']\n",
    "    data_file_path = config_dict['paths']['output']['.data']\n",
    "    train_txt_path = config_dict['paths']['output']['txt_having_paths_to_train_images']\n",
    "    test_txt_path = config_dict['paths']['output']['txt_having_paths_to_test_images']\n",
    "    backup_dir = config_dict['paths']['output']['backup_directory']\n",
    "    cls_names = name_file_path\n",
    "    _, lab_files_path= get_img_lab_files_paths(config_dict)\n",
    "    \n",
    "    ## Get labels name\n",
    "    f = glob.glob(training_data_dir+'*.txt')\n",
    "    category_names_file_path = [  e for e in f if 'classes.txt' in e ][0]\n",
    "    with open(category_names_file_path) as file:\n",
    "            label_name = [ l for l in file.read().split('\\n') if len(l)>0 ]\n",
    "    \n",
    "    ## Get labels id\n",
    "    for i in range(len(lab_files_path)):\n",
    "        with open(lab_files_path[i]) as file:\n",
    "            txt = file.read()\n",
    "        txt_line_li = [ t for t in txt.split('\\n') if len(t.split()) == 5 ]\n",
    "    \n",
    "        ## section/elements in image\n",
    "        all_label_id = []\n",
    "        for sec in txt_line_li:\n",
    "            label_id, rel_x, rel_y, rel_width, rel_height = ( float(e) for e in sec.split() )\n",
    "            label_id = str(int(label_id))\n",
    "            if label_id not in all_label_id: all_label_id.append(label_id)\n",
    "\n",
    "    ## check\n",
    "    if len(label_name) != len(all_label_id):\n",
    "        print('Length of Label Name ({}) is NOT EQUAL to label_id({})'.format(len(label_id), len(label_name)))\n",
    "        raise Exception('There\\'s some issue in total label ids which are present')\n",
    "\n",
    "    ## Generating Label ID Mapping\n",
    "    label_mapping_dict = { i:label_name[i] for i in range(len(label_name)) }\n",
    "    print('Label Mapping:', label_mapping_dict)\n",
    "\n",
    "    ## Generating '.names' file\n",
    "    with open(name_file_path, 'w+') as file:\n",
    "        file.write('\\n'.join(label_name))\n",
    "        print('[File Written] \"{}\" has been written at :\\n\\t{}'.format(\n",
    "            name_file_path.split('/')[-1], name_file_path))\n",
    "\n",
    "    ## Generating '.data' file\n",
    "    n_cls = len(all_label_id)\n",
    "    if os.path.exists(backup_dir) is False: os.mkdir(backup_dir)\n",
    "\n",
    "    txt_for_data = f'classes = {n_cls}\\ntrain =../{train_txt_path}\\nvalid =../{test_txt_path}\"\\\n",
    "    \"\\nnames =../{cls_names}\\nbackup =../{backup_dir}'\n",
    "    \n",
    "    with open(data_file_path, 'w+') as file:\n",
    "        file.write(txt_for_data)\n",
    "        print('[File Written] \"{}\" has been written at :\\n\\t{}'.format(\n",
    "            data_file_path.split('/')[-1], data_file_path))\n",
    "\n",
    "## Creating Required File\n",
    "\n",
    "def main():\n",
    "    '''\n",
    "    config_dict = {\n",
    "        'paths': {\n",
    "            'input': {\n",
    "                'training_data_dir': '../data/processed_data/images_labelled/',\n",
    "            },\n",
    "            'output': {\n",
    "                '.name': '/home/mohit/Documents/CargillWorkspace/ChickenNuggetProblem/ChickenNugget_CV/Frameworks/abc.names',\n",
    "                '.data': '/home/mohit/Documents/CargillWorkspace/ChickenNuggetProblem/ChickenNugget_CV/Frameworks/abc.data',\n",
    "                'txt_having_paths_to_train_images': '/home/mohit/Documents/CargillWorkspace/ChickenNuggetProblem/ChickenNugget_CV/Frameworks/settings/darknet/training_data/train.txt',\n",
    "                'txt_having_paths_to_test_images': '/home/mohit/Documents/CargillWorkspace/ChickenNuggetProblem/ChickenNugget_CV/Frameworks/settings/darknet/training_data/2007_test.txt',\n",
    "                'backup_directory': '/home/mohit/Documents/CargillWorkspace/ChickenNuggetProblem/ChickenNugget_CV/Frameworks/backup',\n",
    "            },\n",
    "        },\n",
    "        'train_size': '0.8'\n",
    "    }\n",
    "    '''\n",
    "    config_dict = {\n",
    "        'paths': {\n",
    "            'input': {\n",
    "                'training_data_dir': IMAGE_LABEL_DIR,\n",
    "            },\n",
    "            'output': {\n",
    "                '.name': DOT_NAMES_FILE_PATH,\n",
    "                '.data': DOT_DATA_FILE_PATH,\n",
    "                'txt_having_paths_to_train_images': TRAIN_IMAGES_PATH_FILE_PATH,\n",
    "                'txt_having_paths_to_test_images': TEST_IMAGES_PATH_FILE_PATH,\n",
    "                'backup_directory': BACKUP_DIR,\n",
    "            },\n",
    "        },\n",
    "        'train_size': TRAIN_SIZE\n",
    "    }\n",
    "    ## Generating the train and test txt files\n",
    "    write_txt_having_paths_to_train_test_images(config_dict)\n",
    "    \n",
    "    ## Generating '.data' & '.name' files\n",
    "    write_data_and_names_files(config_dict)\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone The Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatalogCmdOfDarknet:\n",
    "    def __init__(self):\n",
    "        self.msg_and_cmd_li = []\n",
    "    def add(self, msg, cmd):\n",
    "        self.msg_and_cmd_li.append((msg,cmd))\n",
    "        print(msg, '\\n\\t',cmd)\n",
    "\n",
    "cmd = CatalogCmdOfDarknet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get Darknet Repository \n",
      "\t !cd ../Frameworks/ && git clone https://github.com/AlexeyAB/darknet alexey_darknet\n",
      "Current Directory \n",
      "\t !pwd\n",
      "Files In Current Directory \n",
      "\t !ls -a\n",
      "Files In Framework Directory \n",
      "\t !cd ../Frameworks/darknet/ && ls -a\n"
     ]
    }
   ],
   "source": [
    "cmd.add(\n",
    "    'Get Darknet Repository', \n",
    "    f'!cd {DARKNET_DOWNLOAD_DIR} && git clone https://github.com/AlexeyAB/darknet alexey_darknet'\n",
    ")\n",
    "\n",
    "cmd.add(\n",
    "    'Current Directory', \n",
    "    '!pwd'\n",
    ")\n",
    "\n",
    "cmd.add(\n",
    "    'Files In Current Directory', \n",
    "    '!ls -a'\n",
    ")\n",
    "\n",
    "cmd.add(\n",
    "    'Files In Framework Directory', \n",
    "    f'!cd {DARKNET_DOWNLOAD_DIR}darknet/ && ls -a'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../Frameworks/ && git clone https://github.com/AlexeyAB/darknet alexey_darknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../Frameworks/darknet/ && ls -a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit The Configuration for Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd.add(\n",
    "    'Compile Darknet - Configuration - Load MakeFile', \n",
    "    f'%load {DARKNET_DOWNLOAD_DIR}darknet/Makefile'\n",
    ")\n",
    "\n",
    "cmd.add(\n",
    "    'Compile Darknet - Configuration - Save MakeFile', \n",
    "    f'%%writefile {DARKNET_DOWNLOAD_DIR}darknet/Makefile'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd.add(\n",
    "    'Compile Darknet', \n",
    "    f'!cd {DARKNET_DOWNLOAD_DIR}darknet && make'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../Frameworks/darknet && make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Successful Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd.add(\n",
    "    'Check Sucessful Build', \n",
    "    f'!cd {DARKNET_DOWNLOAD_DIR}darknet && ./darknet'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../Frameworks/darknet && ./darknet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Weight Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Location of Configs and Weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd.add('Directories inside framework/settings/darknet', '!ls ../config/darknet_cfgs_convs_weights/downloaded/')\n",
    "# cmd.add('Directories inside framework/settings/darknet', '!ls -lsh settings/darknet/configs/')\n",
    "# cmd.add('Directories inside framework/settings/darknet', '!ls -lsh settings/darknet/weights/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../config/darknet_cfgs_convs_weights/downloaded/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Detection Using A Pre-Trained Model\n",
    "\n",
    "\n",
    "cmd.add(\n",
    "    'Testing Model - Single Image - Way1',\n",
    "    f'!cd {DARKNET_DOWNLOAD_DIR}darknet && ./darknet detect ../{CONFIG_TO_USE_FILE_PATH} ../{WEIGHTS_TO_LOAD_FILE_PATH} ../{TEST_IMAGE_PATH} -thresh {THRESHOLD_TO_USE}'\n",
    ")\n",
    "\n",
    "\n",
    "# cfg/obj.data cfg/yolov3-voc.cfg backup/yolov3-voc_last.weights data/bc.JPG\n",
    "cmd.add(\n",
    "    'Testing Model - Single Image - Way2',\n",
    "    f'!cd {DARKNET_DOWNLOAD_DIR}darknet && ./darknet detector test ../{DOT_DATA_FILE_PATH} ../{CONFIG_TO_USE_FILE_PATH} ../{WEIGHTS_TO_LOAD_FILE_PATH} ../{TEST_IMAGE_PATH} -thresh {THRESHOLD_TO_USE}'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../Frameworks/darknet && ./darknet detect ../../config/darknet_cfgs_convs_weights/downloaded/YOLOv3-608.cfg ../../config/darknet_cfgs_convs_weights/downloaded/YOLOv3-608.weights ../../data/processed_data/images_labelled/172_0_2834.jpeg -thresh 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../Frameworks/darknet && ./darknet detector test ../../data/processed_data/nuggets.data ../../config/darknet_cfgs_convs_weights/downloaded/YOLOv3-608.cfg ../../config/darknet_cfgs_convs_weights/downloaded/YOLOv3-608.weights ../../data/processed_data/images_labelled/172_0_2834.jpeg -thresh 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing on Multiple Images\n",
    "\n",
    "cmd.add(\n",
    "    'Testing Model - Multiple Image',\n",
    "    f'!cd {DARKNET_DOWNLOAD_DIR}darknet && ./darknet detect ../{CONFIG_TO_USE_FILE_PATH} ../{WEIGHTS_TO_LOAD_FILE_PATH} -thresh {THRESHOLD_TO_USE}'\n",
    ")\n",
    "# Image path in console\n",
    "\n",
    "## Real Time Detection on Webcam\n",
    "''' \n",
    "-c <num> to pick (OpenCV uses webcam 0 by default).\n",
    "'''\n",
    "cmd.add(\n",
    "    'Testing Model - OpenCV - using default camera',\n",
    "    f'!cd {DARKNET_DOWNLOAD_DIR}darknet && ./darknet detector demo ../{DOT_DATA_FILE_PATH} ../{CONFIG_TO_USE_FILE_PATH} ../{WEIGHTS_TO_LOAD_FILE_PATH} -c 0'\n",
    ")\n",
    "\n",
    "cmd.add(\n",
    "    'Testing Model - OpenCV - Video File',\n",
    "    f'!cd {DARKNET_DOWNLOAD_DIR}darknet && ./darknet detector demo ../{DOT_DATA_FILE_PATH} ../{CONFIG_TO_USE_FILE_PATH} ../{WEIGHTS_TO_LOAD_FILE_PATH} <video file>'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../Frameworks/darknet && ./darknet detect ../../config/darknet_cfgs_convs_weights/downloaded/YOLOv3-608.cfg ../../config/darknet_cfgs_convs_weights/downloaded/YOLOv3-608.weights -thresh 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nohup ./darknet detector train cfg/obj.data cfg/yolov3-voc.cfg darknet53.conv.74>training_yolov3_voc_defect_1.txt\n",
    "\n",
    "cmd.add(\n",
    "    'Training the Model',\n",
    "    f'!cd {DARKNET_DOWNLOAD_DIR}darknet && ./darknet detector train ../{DOT_DATA_FILE_PATH} ../{CONFIG_TO_USE_FILE_PATH} ../{CONVOLUTION_LAYER_FILE_PATH}'\n",
    ")\n",
    "\n",
    "## multiple gpus run:\n",
    "cmd.add(\n",
    "    'Training the Model',\n",
    "    f'!cd {DARKNET_DOWNLOAD_DIR}darknet && ./darknet detector train ../{DOT_DATA_FILE_PATH} ../{CONFIG_TO_USE_FILE_PATH} ../{CONVOLUTION_LAYER_FILE_PATH} -gpus 0,1,2,3'\n",
    ")\n",
    "\n",
    "## stop and restart training from a checkpoint\n",
    "cmd.add(\n",
    "    'Training the Model',\n",
    "    f'!cd {DARKNET_DOWNLOAD_DIR}darknet && ./darknet detector train ../{DOT_DATA_FILE_PATH} ../{CONFIG_TO_USE_FILE_PATH} <backup> -gpus 0,1,2,3'\n",
    ")\n",
    "\n",
    "# ./darknet detector train cfg/coco.data cfg/yolov3.cfg backup/yolov3.backup -gpus 0,1,2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../Frameworks/darknet && ./darknet detector train ../../data/processed_data/nuggets.data ../../config/darknet_cfgs_convs_weights/downloaded/YOLOv3-608.cfg ../../config/darknet_cfgs_convs_weights/downloaded/darknet53.conv.74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training YOLO on VOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get The Pascal VOC Data\n",
    "\n",
    "wget https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar\n",
    "wget https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar\n",
    "wget https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar\n",
    "tar xf VOCtrainval_11-May-2012.tar\n",
    "tar xf VOCtrainval_06-Nov-2007.tar\n",
    "tar xf VOCtest_06-Nov-2007.tar\n",
    "\n",
    "## Generate Labels for VOC\n",
    "# <object-class> <x> <y> <width> <height>\n",
    "wget https://pjreddie.com/media/files/voc_label.py\n",
    "python voc_label.py\n",
    "\n",
    "ls\n",
    "'''\n",
    "2007_test.txt   VOCdevkit\n",
    "2007_train.txt  voc_label.py\n",
    "2007_val.txt    VOCtest_06-Nov-2007.tar\n",
    "2012_train.txt  VOCtrainval_06-Nov-2007.tar\n",
    "2012_val.txt    VOCtrainval_11-May-2012.tar\n",
    "'''\n",
    "cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt\n",
    "\n",
    "## Modify Cfg for Pascal Data:  cfg/voc.data\n",
    "1 classes= 20\n",
    "2 train  = <path-to-voc>/train.txt\n",
    "3 valid  = <path-to-voc>2007_test.txt\n",
    "4 names = data/voc.names\n",
    "5 backup = backup\n",
    "\n",
    "## Download Pretrained Convolutional Weights\n",
    "wget https://pjreddie.com/media/files/darknet53.conv.74\n",
    "\n",
    "## Train The Model\n",
    "./darknet detector train cfg/voc.data cfg/yolov3-voc.cfg darknet53.conv.74\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/home/mohit/Documents/CargillWorkspace/ChickenNuggetProblem/ChickenNugget_CV/Frameworks/settings/darknet/'\n",
    "config_path = directory + 'configs/yolov3.cfg'\n",
    "# weights_path = directory + 'weights/yolov3.weights'\n",
    "# image_path = directory + 'sample_image/dog.jpg'\n",
    "data_path = directory + 'voc.data'\n",
    "# threshold_score = 0.25\n",
    "\n",
    "conv_path = directory + 'configs/darknet53.conv.74'\n",
    "cmd_to_run.append(f'!cd darknet && ./darknet detector train {data_path} {config_path} {conv_path}')\n",
    "cmd_to_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!cd darknet && ./darknet detector train /home/mohit/Documents/CargillWorkspace/ChickenNuggetProblem/ChickenNugget_CV/Frameworks/settings/darknet/voc.data /home/mohit/Documents/CargillWorkspace/ChickenNuggetProblem/ChickenNugget_CV/Frameworks/settings/darknet/configs/yolov3.cfg /home/mohit/Documents/CargillWorkspace/ChickenNuggetProblem/ChickenNugget_CV/Frameworks/settings/darknet/configs/darknet53.conv.74"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training YOLO on COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get The COCO Data\n",
    "cp scripts/get_coco_dataset.sh data\n",
    "cd data\n",
    "bash get_coco_dataset.sh\n",
    "\n",
    "## Modify cfg for COCO : cfg/coco.data\n",
    "1 classes= 80\n",
    "2 train  = <path-to-coco>/trainvalno5k.txt\n",
    "3 valid  = <path-to-coco>/5k.txt\n",
    "4 names = data/coco.names\n",
    "5 backup = backup\n",
    "\n",
    "## Modify cfg for COCO :  cfg/yolo.cfg\n",
    "[net]\n",
    "# Testing\n",
    "# batch=1\n",
    "# subdivisions=1\n",
    "# Training\n",
    "batch=64\n",
    "subdivisions=8\n",
    "....\n",
    "\n",
    "## Train The Model\n",
    "./darknet detector train cfg/coco.data cfg/yolov3.cfg darknet53.conv.74\n",
    "\n",
    "-- multiple gpus run:\n",
    "    ./darknet detector train cfg/coco.data cfg/yolov3.cfg darknet53.conv.74 -gpus 0,1,2,3\n",
    "-- stop and restart training from a checkpoint\n",
    "    ./darknet detector train cfg/coco.data cfg/yolov3.cfg backup/yolov3.backup -gpus 0,1,2,3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOLOv3 on the Open Images dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wget https://pjreddie.com/media/files/yolov3-openimages.weights\n",
    "\n",
    "./darknet detector test cfg/openimages.data cfg/yolov3-openimages.cfg yolov3-openimages.weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# old Other Code Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run $filename.py {args[0]} {args[1][-2:]}\n",
    "\n",
    "# import subprocess\n",
    "# # cmd = cmd_to_run.split()\n",
    "# print(f'Running the command: {cmd_to_run}')\n",
    "# output = subprocess.run( cmd_to_run, shell=True, check=False)#, capture_output=True)\n",
    "# print(output.stdout.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WHICH_REPO = 'Original_Darknet' # Original_Darknet, AlexeyAB_Darknet, ultralytics_Darknet, matterport_Mask_RCNN\n",
    "\n",
    "cmd_to_run = ['!git clone ' ]\n",
    "if 'Original_Darknet':\n",
    "    cmd_to_run[0] += 'https://github.com/pjreddie/darknet'\n",
    "elif 'AlexeyAB_Darknet':\n",
    "    cmd_to_run[0] += 'https://github.com/AlexeyAB/darknet'\n",
    "elif 'ultralytics_Darknet':\n",
    "    cmd_to_run[0] += 'https://github.com/ultralytics/yolov3'\n",
    "elif 'matterport_Mask_RCNN':\n",
    "    cmd_to_run[0] += 'https://github.com/matterport/Mask_RCNN'\n",
    "\n",
    "print('Clone Repository:\\n\\t', '\\n\\t'.join(cmd_to_run))\n",
    "\n",
    "cmd_to_run.append('!ls -a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####################### Image Format Changing #################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# from os import walk, getcwd\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "cls = \"stopsign\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_img_path = '../data/processed_data/images_labelled/'\n",
    "out_path = '../data/processed_data/'\n",
    "classes = [\"stopsign\"] ## can be read from data.names\n",
    "\n",
    "def check_allowed_class(cls):\n",
    "    if cls not in classes:\n",
    "        raise Exception(f'Error: {cls} is not present in the {classes}.')\n",
    "        \n",
    "def convert_to_class_id(cls):\n",
    "    return classes.index(cls)\n",
    "\n",
    "\n",
    "img_txt_files_path = glob.glob(in_img_path+'*.txt')\n",
    "img_txt_files_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '../data/processed_data/images_labelled/172_0_6255.jpeg'#img_txt_files_path[0]\n",
    "img_path\n",
    "\n",
    "import cv2\n",
    "\n",
    "def convert_labels(size, x1, y1, x2, y2):\n",
    "    \"\"\"\n",
    "    Definition: Parses label files to extract label and bounding box\n",
    "        coordinates.  Converts (x1, y1, x1, y2) KITTI format to\n",
    "        (x, y, width, height) normalized YOLO format.\n",
    "    \"\"\"\n",
    "    def sorting(l1, l2):\n",
    "        if l1 > l2:\n",
    "            lmax, lmin = l1, l2\n",
    "            return lmax, lmin\n",
    "        else:\n",
    "            lmax, lmin = l2, l1\n",
    "            return lmax, lmin\n",
    "    size = get_img_shape(path)\n",
    "    xmax, xmin = sorting(x1, x2)\n",
    "    ymax, ymin = sorting(y1, y2)\n",
    "    dw = 1./size[1]\n",
    "    dh = 1./size[0]\n",
    "    x = (xmin + xmax)/2.0\n",
    "    y = (ymin + ymax)/2.0\n",
    "    w = xmax - xmin\n",
    "    h = ymax - ymin\n",
    "    x = x*dw\n",
    "    w = w*dw\n",
    "    y = y*dh\n",
    "    h = h*dh\n",
    "    return (x,y,w,h)\n",
    "\n",
    "\n",
    "def get_img_shape(path):\n",
    "#     path = 'data/'+path\n",
    "    img = cv2.imread(path)\n",
    "    try:\n",
    "        return img.shape\n",
    "    except AttributeError:\n",
    "        print('error! ', path)\n",
    "        return (None, None, None)\n",
    "\n",
    "\n",
    "convert_labels(size, x1, y1, x2, y2)\n",
    "\n",
    "img_dict = {}\n",
    "img_dict['path'] = img_path\n",
    "img_dict['path']['shape'] = get_img_shape(img_path)\n",
    "img_dict['path']['sections'] = {} \n",
    "\n",
    "## categories [options - labels / sections in a image]\n",
    "img_dict['path']['sections'+s]['Normalized'] = {} \n",
    "\n",
    "\n",
    "# bbox_img['x'], bbox_img['y'], bbox_img['width'], bbox_img['height'] = zip(*bbox_img.progress_apply(lambda row: convert_labels(row['Path'], row['x1'], row['y1'], row['x2'], row['y2']), axis=1)) # Like python for one lone code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_ima\n",
    "\n",
    "def convert(size, box_coordinate):\n",
    "    '''\n",
    "     Converts (x1, y1, x1, y2) KITTI format to (x, y, width, height) normalized YOLO format\n",
    "    \n",
    "    box_coordinate = (x1, y1, x2, y2)\n",
    "    '''\n",
    "    def sorting(l1, l2):\n",
    "        if l1 > l2:\n",
    "            lmax, lmin = l1, l2\n",
    "            return lmax, lmin\n",
    "        else:\n",
    "            lmax, lmin = l2, l1\n",
    "            return lmax, lmin\n",
    "    size = get_img_shape(path)\n",
    "    xmax, xmin = sorting(x1, x2)\n",
    "    ymax, ymin = sorting(y1, y2)\n",
    "    dw = 1./size[1]\n",
    "    dh = 1./size[0]\n",
    "    x = (xmin + xmax)/2.0\n",
    "    y = (ymin + ymax)/2.0\n",
    "    w = xmax - xmin\n",
    "    h = ymax - ymin\n",
    "    x = x*dw\n",
    "    w = w*dw\n",
    "    y = y*dh\n",
    "    h = h*dh\n",
    "    return (x_min, ymin, x_max, y_max), (x,y,w,h)\n",
    "\n",
    "    \n",
    "    dw = 1./size[0]\n",
    "    dh = 1./size[1]\n",
    "    x = (box[0] + box[1])/2.0\n",
    "    y = (box[2] + box[3])/2.0\n",
    "    w = box[1] - box[0]\n",
    "    h = box[3] - box[2]\n",
    "    x = x*dw\n",
    "    w = w*dw\n",
    "    y = y*dh\n",
    "    h = h*dh\n",
    "    return (x,y,w,h)\n",
    "\n",
    "\n",
    "def process_a_file(file_path):\n",
    "    ''' '''\n",
    "    ## Open txt files\n",
    "    with open(img_txt_files_path[i]) as file:\n",
    "        txt = file.read()\n",
    "    txt_line_li = [ t for t in txt.split('\\n') if len(t.split()) == 5 ]\n",
    "#     txt_line_li\n",
    "    \n",
    "    ## Convert To Yolo Format \n",
    "    count = 0\n",
    "    for line in txt_line_li:\n",
    "        print(line)\n",
    "        xmin, ymin, x_max, y_max = line.split()\n",
    "        \n",
    "\n",
    "\n",
    "for i in range(len(img_txt_files_path)):\n",
    "    \n",
    "#     \"\"\" Open output text files \"\"\"\n",
    "#     txt_outpath = outpath + txt_name\n",
    "#     print(\"Output:\" + txt_outpath)\n",
    "#     txt_outfile = open(txt_outpath, \"w\")\n",
    "    \n",
    "    \n",
    "#     \"\"\" Convert the data to YOLO format \"\"\"\n",
    "#     ct = 0\n",
    "#     for line in lines:\n",
    "#         #print('lenth of line is: ')\n",
    "#         #print(len(line))\n",
    "#         #print('\\n')\n",
    "#         if(len(line) >= 2):\n",
    "#             ct = ct + 1\n",
    "#             print(line + \"\\n\")\n",
    "#             elems = line.split(' ')\n",
    "#             print(elems)\n",
    "#             xmin = elems[0]\n",
    "#             xmax = elems[2]\n",
    "#             ymin = elems[1]\n",
    "#             ymax = elems[3]\n",
    "#             #\n",
    "#             img_path = str('%s/images/%s/%s.JPEG'%(wd, cls, os.path.splitext(txt_name)[0]))\n",
    "#             #t = magic.from_file(img_path)\n",
    "#             #wh= re.search('(\\d+) x (\\d+)', t).groups()\n",
    "#             im=Image.open(img_path)\n",
    "#             w= int(im.size[0])\n",
    "#             h= int(im.size[1])\n",
    "#             #w = int(xmax) - int(xmin)\n",
    "#             #h = int(ymax) - int(ymin)\n",
    "#             # print(xmin)\n",
    "#             print(w, h)\n",
    "#             b = (float(xmin), float(xmax), float(ymin), float(ymax))\n",
    "#             bb = convert((w,h), b)\n",
    "#             print(bb)\n",
    "#             txt_outfile.write(str(cls_id) + \" \" + \" \".join([str(a) for a in bb]) + '\\n')\n",
    "\n",
    "#     \"\"\" Save those images with bb into list\"\"\"\n",
    "#     if(ct != 0):\n",
    "#         list_file.write('%s/images/%s/%s.JPEG\\n'%(wd, cls, os.path.splitext(txt_name)[0]))\n",
    "\n",
    "    ## Progress Msg\n",
    "    if i==0: print('Data Processing Initiated')\n",
    "    if (i+1)%10==0: print('Processed {:03d}/{}'.format(i+1, len(img_txt_files_path)))\n",
    "    if i+1==len(img_txt_files_path): print('[Complete] Processed {o}/{o}'.format(o=len(img_txt_files_path)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from os import walk, getcwd\n",
    "# from PIL import Image\n",
    "\n",
    "# classes = [\"stopsign\"]\n",
    "\n",
    "# def convert(size, box):\n",
    "#     dw = 1./size[0]\n",
    "#     dh = 1./size[1]\n",
    "#     x = (box[0] + box[1])/2.0\n",
    "#     y = (box[2] + box[3])/2.0\n",
    "#     w = box[1] - box[0]\n",
    "#     h = box[3] - box[2]\n",
    "#     x = x*dw\n",
    "#     w = w*dw\n",
    "#     y = y*dh\n",
    "#     h = h*dh\n",
    "#     return (x,y,w,h)\n",
    "    \n",
    "    \n",
    "# \"\"\"-------------------------------------------------------------------\"\"\" \n",
    "\n",
    "# \"\"\" Configure Paths\"\"\"   \n",
    "# mypath = \"labels/stopsign_original/\"\n",
    "# outpath = \"labels/stopsign/\"\n",
    "\n",
    "# cls = \"stopsign\"\n",
    "# if cls not in classes:\n",
    "#     exit(0)\n",
    "# cls_id = classes.index(cls)\n",
    "\n",
    "# wd = getcwd()\n",
    "# list_file = open('%s/%s_list.txt'%(wd, cls), 'w')\n",
    "\n",
    "# \"\"\" Get input text file list \"\"\"\n",
    "# txt_name_list = []\n",
    "# for (dirpath, dirnames, filenames) in walk(mypath):\n",
    "#     txt_name_list.extend(filenames)\n",
    "#     break\n",
    "# print(txt_name_list)\n",
    "\n",
    "\"\"\" Process \"\"\"\n",
    "for txt_name in txt_name_list:\n",
    "    # txt_file =  open(\"Labels/stop_sign/001.txt\", \"r\")\n",
    "    \n",
    "    \"\"\" Open input text files \"\"\"\n",
    "    txt_path = mypath + txt_name\n",
    "    print(\"Input:\" + txt_path)\n",
    "    txt_file = open(txt_path, \"r\")\n",
    "    lines = txt_file.read().split('\\r\\n')   #for ubuntu, use \"\\r\\n\" instead of \"\\n\"\n",
    "    \n",
    "    \"\"\" Open output text files \"\"\"\n",
    "    txt_outpath = outpath + txt_name\n",
    "    print(\"Output:\" + txt_outpath)\n",
    "    txt_outfile = open(txt_outpath, \"w\")\n",
    "    \n",
    "    \n",
    "    \"\"\" Convert the data to YOLO format \"\"\"\n",
    "    ct = 0\n",
    "    for line in lines:\n",
    "        #print('lenth of line is: ')\n",
    "        #print(len(line))\n",
    "        #print('\\n')\n",
    "        if(len(line) >= 2):\n",
    "            ct = ct + 1\n",
    "            print(line + \"\\n\")\n",
    "            elems = line.split(' ')\n",
    "            print(elems)\n",
    "            xmin = elems[0]\n",
    "            xmax = elems[2]\n",
    "            ymin = elems[1]\n",
    "            ymax = elems[3]\n",
    "            #\n",
    "            img_path = str('%s/images/%s/%s.JPEG'%(wd, cls, os.path.splitext(txt_name)[0]))\n",
    "            #t = magic.from_file(img_path)\n",
    "            #wh= re.search('(\\d+) x (\\d+)', t).groups()\n",
    "            im=Image.open(img_path)\n",
    "            w= int(im.size[0])\n",
    "            h= int(im.size[1])\n",
    "            #w = int(xmax) - int(xmin)\n",
    "            #h = int(ymax) - int(ymin)\n",
    "            # print(xmin)\n",
    "            print(w, h)\n",
    "            b = (float(xmin), float(xmax), float(ymin), float(ymax))\n",
    "            bb = convert((w,h), b)\n",
    "            print(bb)\n",
    "            txt_outfile.write(str(cls_id) + \" \" + \" \".join([str(a) for a in bb]) + '\\n')\n",
    "\n",
    "    \"\"\" Save those images with bb into list\"\"\"\n",
    "    if(ct != 0):\n",
    "        list_file.write('%s/images/%s/%s.JPEG\\n'%(wd, cls, os.path.splitext(txt_name)[0]))\n",
    "                \n",
    "list_file.close()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Preparation For Yolo\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import pickle\n",
    "import os\n",
    "from os import listdir, getcwd\n",
    "from os.path import join\n",
    "\n",
    "sets=[('2012', 'train'), ('2012', 'val'), ('2007', 'train'), ('2007', 'val'), ('2007', 'test')]\n",
    "\n",
    "classes = [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "\n",
    "def convert(size, box):\n",
    "    dw = 1./size[0]\n",
    "    dh = 1./size[1]\n",
    "    x = (box[0] + box[1])/2.0\n",
    "    y = (box[2] + box[3])/2.0\n",
    "    w = box[1] - box[0]\n",
    "    h = box[3] - box[2]\n",
    "    x = x*dw\n",
    "    w = w*dw\n",
    "    y = y*dh\n",
    "    h = h*dh\n",
    "    return (x,y,w,h)\n",
    "\n",
    "def convert_annotation(year, image_id):\n",
    "    in_file = open('VOCdevkit/VOC%s/Annotations/%s.xml'%(year, image_id))\n",
    "    out_file = open('VOCdevkit/VOC%s/labels/%s.txt'%(year, image_id), 'w')\n",
    "    tree=ET.parse(in_file)\n",
    "    root = tree.getroot()\n",
    "    size = root.find('size')\n",
    "    w = int(size.find('width').text)\n",
    "    h = int(size.find('height').text)\n",
    "\n",
    "    for obj in root.iter('object'):\n",
    "        difficult = obj.find('difficult').text\n",
    "        cls = obj.find('name').text\n",
    "        if cls not in classes or int(difficult) == 1:\n",
    "            continue\n",
    "        cls_id = classes.index(cls)\n",
    "        xmlbox = obj.find('bndbox')\n",
    "        b = (float(xmlbox.find('xmin').text), float(xmlbox.find('xmax').text), float(xmlbox.find('ymin').text), float(xmlbox.find('ymax').text))\n",
    "        bb = convert((w,h), b)\n",
    "        out_file.write(str(cls_id) + \" \" + \" \".join([str(a) for a in bb]) + '\\n')\n",
    "\n",
    "wd = getcwd()\n",
    "\n",
    "for year, image_set in sets:\n",
    "    if not os.path.exists('VOCdevkit/VOC%s/labels/'%(year)):\n",
    "        os.makedirs('VOCdevkit/VOC%s/labels/'%(year))\n",
    "    image_ids = open('VOCdevkit/VOC%s/ImageSets/Main/%s.txt'%(year, image_set)).read().strip().split()\n",
    "    list_file = open('%s_%s.txt'%(year, image_set), 'w')\n",
    "    for image_id in image_ids:\n",
    "        list_file.write('%s/VOCdevkit/VOC%s/JPEGImages/%s.jpg\\n'%(wd, year, image_id))\n",
    "        convert_annotation(year, image_id)\n",
    "    list_file.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyPersonalEnv",
   "language": "python",
   "name": "mypersonalenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
