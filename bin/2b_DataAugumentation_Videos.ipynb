{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://kkroening.github.io/ffmpeg-python/\n",
    "https://github.com/kkroening/ffmpeg-python/tree/master/examples\n",
    "https://kkroening.github.io/ffmpeg-python/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/raw_data/video/594371324.545536.mp4',\n",
       " '../data/raw_data/video/594371324.037443.mp4',\n",
       " '../data/raw_data/video/594371324.202440.mp4',\n",
       " '../data/raw_data/video/594371324.732749.mp4',\n",
       " '../data/raw_data/video/594371324.375344.mp4',\n",
       " '../data/raw_data/video/594371324.126019.mp4',\n",
       " '../data/raw_data/video/594371323.935324.mp4',\n",
       " '../data/raw_data/video/594371324.458069.mp4',\n",
       " '../data/raw_data/video/594371324.293383.mp4']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob, time\n",
    "import ffmpeg, numpy as np\n",
    "\n",
    "VIDEO_DIR = '../data/raw_data/video/'\n",
    "\n",
    "files = glob.glob(VIDEO_DIR+'*')\n",
    "vid_files = [ f for f in files if f.split('.')[-1].lower() in ['mp4', '3gp', 'avi'] ]\n",
    "vid_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/raw_data/video/594371324.545536.mp4  >>  ../data/raw_data/temppp.mp4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file_path = vid_files[0]\n",
    "output_file_path = '../data/raw_data/temppp.mp4'\n",
    "\n",
    "''.join([input_file_path, '  >>  ', output_file_path])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get video info (ffprobe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3840 2160 136\n",
      "{'streams': [{'index': 0, 'codec_name': 'h264', 'codec_long_name': 'H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10', 'profile': 'High', 'codec_type': 'video', 'codec_time_base': '1001/48000', 'codec_tag_string': 'avc1', 'codec_tag': '0x31637661', 'width': 3840, 'height': 2160, 'coded_width': 3840, 'coded_height': 2160, 'has_b_frames': 0, 'sample_aspect_ratio': '1:1', 'display_aspect_ratio': '16:9', 'pix_fmt': 'yuvj420p', 'level': 51, 'color_range': 'pc', 'color_space': 'bt709', 'color_transfer': 'bt709', 'color_primaries': 'bt709', 'chroma_location': 'left', 'refs': 1, 'is_avc': 'true', 'nal_length_size': '4', 'r_frame_rate': '24000/1001', 'avg_frame_rate': '24000/1001', 'time_base': '1/24000', 'start_pts': 0, 'start_time': '0.000000', 'duration_ts': 136136, 'duration': '5.672333', 'bit_rate': '66806828', 'bits_per_raw_sample': '8', 'nb_frames': '136', 'disposition': {'default': 1, 'dub': 0, 'original': 0, 'comment': 0, 'lyrics': 0, 'karaoke': 0, 'forced': 0, 'hearing_impaired': 0, 'visual_impaired': 0, 'clean_effects': 0, 'attached_pic': 0, 'timed_thumbnails': 0}, 'tags': {'creation_time': '1980-09-27T07:00:28.000000Z', 'language': 'eng', 'handler_name': '\\x0bGoPro AVC  ', 'encoder': 'GoPro AVC encoder', 'timecode': '14:03:03:14'}}, {'index': 1, 'codec_name': 'aac', 'codec_long_name': 'AAC (Advanced Audio Coding)', 'profile': 'LC', 'codec_type': 'audio', 'codec_time_base': '1/48000', 'codec_tag_string': 'mp4a', 'codec_tag': '0x6134706d', 'sample_fmt': 'fltp', 'sample_rate': '48000', 'channels': 2, 'channel_layout': 'stereo', 'bits_per_sample': 0, 'r_frame_rate': '0/0', 'avg_frame_rate': '0/0', 'time_base': '1/48000', 'start_pts': 0, 'start_time': '0.000000', 'duration_ts': 271360, 'duration': '5.653333', 'bit_rate': '190426', 'max_bit_rate': '48000', 'nb_frames': '265', 'disposition': {'default': 1, 'dub': 0, 'original': 0, 'comment': 0, 'lyrics': 0, 'karaoke': 0, 'forced': 0, 'hearing_impaired': 0, 'visual_impaired': 0, 'clean_effects': 0, 'attached_pic': 0, 'timed_thumbnails': 0}, 'tags': {'creation_time': '1980-09-27T07:00:28.000000Z', 'language': 'eng', 'handler_name': '\\x0bGoPro AAC  ', 'timecode': '14:03:03:14'}}, {'index': 2, 'codec_type': 'data', 'codec_tag_string': 'tmcd', 'codec_tag': '0x64636d74', 'r_frame_rate': '0/0', 'avg_frame_rate': '23/1', 'time_base': '1/24000', 'start_pts': 0, 'start_time': '0.000000', 'duration_ts': 136136, 'duration': '5.672333', 'bit_rate': '5', 'nb_frames': '1', 'disposition': {'default': 1, 'dub': 0, 'original': 0, 'comment': 0, 'lyrics': 0, 'karaoke': 0, 'forced': 0, 'hearing_impaired': 0, 'visual_impaired': 0, 'clean_effects': 0, 'attached_pic': 0, 'timed_thumbnails': 0}, 'tags': {'creation_time': '1980-09-27T07:00:28.000000Z', 'language': 'eng', 'handler_name': '\\x0bGoPro TCD  ', 'timecode': '14:03:03:14'}}, {'index': 3, 'codec_name': 'bin_data', 'codec_long_name': 'binary data', 'codec_type': 'data', 'codec_tag_string': 'gpmd', 'codec_tag': '0x646d7067', 'r_frame_rate': '0/0', 'avg_frame_rate': '0/0', 'time_base': '1/1000', 'start_pts': 0, 'start_time': '0.000000', 'duration_ts': 5672, 'duration': '5.672000', 'bit_rate': '35203', 'nb_frames': '5', 'disposition': {'default': 1, 'dub': 0, 'original': 0, 'comment': 0, 'lyrics': 0, 'karaoke': 0, 'forced': 0, 'hearing_impaired': 0, 'visual_impaired': 0, 'clean_effects': 0, 'attached_pic': 0, 'timed_thumbnails': 0}, 'tags': {'creation_time': '1980-09-27T07:00:28.000000Z', 'language': 'eng', 'handler_name': '\\x0bGoPro MET  '}}, {'index': 4, 'codec_type': 'data', 'codec_tag_string': 'fdsc', 'codec_tag': '0x63736466', 'r_frame_rate': '0/0', 'avg_frame_rate': '0/0', 'time_base': '1/24000', 'start_pts': 0, 'start_time': '0.000000', 'duration_ts': 136136, 'duration': '5.672333', 'bit_rate': '10165', 'nb_frames': '408', 'disposition': {'default': 1, 'dub': 0, 'original': 0, 'comment': 0, 'lyrics': 0, 'karaoke': 0, 'forced': 0, 'hearing_impaired': 0, 'visual_impaired': 0, 'clean_effects': 0, 'attached_pic': 0, 'timed_thumbnails': 0}, 'tags': {'creation_time': '1980-09-27T07:00:28.000000Z', 'language': 'eng', 'handler_name': '\\x0bGoPro SOS  '}}], 'format': {'filename': '../data/raw_data/video/594371324.545536.mp4', 'nb_streams': 5, 'nb_programs': 0, 'format_name': 'mov,mp4,m4a,3gp,3g2,mj2', 'format_long_name': 'QuickTime / MOV', 'start_time': '0.000000', 'duration': '5.672333', 'size': '47568093', 'bit_rate': '67087870', 'probe_score': 100, 'tags': {'major_brand': 'mp41', 'minor_version': '538120216', 'compatible_brands': 'mp41', 'creation_time': '1980-09-27T07:00:28.000000Z', 'firmware': 'HD6.01.02.01.00'}}}\n"
     ]
    }
   ],
   "source": [
    "probe = ffmpeg.probe(input_file_path)\n",
    "video_info = next((stream for stream in probe['streams'] if stream['codec_type'] == 'video'), None)\n",
    "width = int(video_info['width'])\n",
    "height = int(video_info['height'])\n",
    "num_frames = int(video_info['nb_frames'])\n",
    "\n",
    "print(width, height, num_frames)\n",
    "print(probe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate thumbnail for video\n",
    "![](https://raw.githubusercontent.com/kkroening/ffmpeg-python/master/examples/graphs/get_video_thumbnail.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "\n",
    "stream = ffmpeg.input(input_file_path)\n",
    "stream = ffmpeg.hflip(stream)\n",
    "stream = ffmpeg.output(stream, 'output.mp4')\n",
    "ffmpeg.run(stream)\n",
    "\n",
    "# (\n",
    "#     ffmpeg\n",
    "#     .input('input.mp4')\n",
    "#     .hflip()\n",
    "#     .output('output.mp4')\n",
    "#     .run()\n",
    "# )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "\n",
    "in_file = ffmpeg.input('input.mp4')\n",
    "overlay_file = ffmpeg.input('overlay.png')\n",
    "(\n",
    "    ffmpeg\n",
    "    .concat(\n",
    "        in_file.trim(start_frame=10, end_frame=20),\n",
    "        in_file.trim(start_frame=30, end_frame=40),\n",
    "    )\n",
    "    .overlay(overlay_file.hflip())\n",
    "    .drawbox(50, 50, 120, 120, color='red', thickness=5)\n",
    "    .output('out.mp4')\n",
    "    .run()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://kkroening.github.io/ffmpeg-python/\n",
    "https://github.com/kkroening/ffmpeg-python\n",
    "\n",
    "\n",
    "# input = ffmpeg.input('in.mp4')\n",
    "# audio = input.audio.filter(\"aecho\", 0.8, 0.9, 1000, 0.3)\n",
    "# video = input.video.hflip()\n",
    "# out = ffmpeg.output(audio, video, 'out.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## custom filters\n",
    "\n",
    "stream = ffmpeg.input('dummy.mp4')\n",
    "stream = ffmpeg.filter(stream, 'fps', fps=25, round='up')\n",
    "stream = ffmpeg.output(stream, 'dummy2.mp4')\n",
    "ffmpeg.run(stream)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ffmpeg\n",
    "    .input('in.mp4')\n",
    "    .output('out.mp4', **{'qscale:v': 3})\n",
    "    .run()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multiple Input\n",
    "\n",
    "main = ffmpeg.input('main.mp4')\n",
    "logo = ffmpeg.input('logo.png')\n",
    "(\n",
    "    ffmpeg\n",
    "    .filter([main, logo], 'overlay', 10, 10)\n",
    "    .output('out.mp4')\n",
    "    .run()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multiple Output\n",
    "split = (\n",
    "    ffmpeg\n",
    "    .input('in.mp4')\n",
    "    .filter_multi_output('split')  # or `.split()`\n",
    ")\n",
    "(\n",
    "    ffmpeg\n",
    "    .concat(split[0], split[1].reverse())\n",
    "    .output('out.mp4')\n",
    "    .run()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## String Expression\n",
    "(\n",
    "    ffmpeg\n",
    "    .input('in.mp4')\n",
    "    .filter('crop', 'in_w-2*10', 'in_h-2*20')\n",
    "    .input('out.mp4')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ffmpeg.input(input_file_path, ss=time)\n",
    "print(type(f))\n",
    "print(f)\n",
    "f = f.filter('scale', width, -1)\n",
    "print(type(f))\n",
    "print(f)\n",
    "f = f.output(output_file_path, vframes=1)\n",
    "print(type(f))\n",
    "print(f)\n",
    "ffmpeg.run(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print(\"fatal error\", file=sys.stderr)\n",
    "\n",
    "print(str(sys.stderr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ffmpeg\n",
    "    .input(input_file_path, ss=time)\n",
    "    .filter('scale', width, -1)\n",
    "    .output(output_file_path, vframes=1)\n",
    "    .run()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert video to numpy array\n",
    "\n",
    "![](https://raw.githubusercontent.com/kkroening/ffmpeg-python/master/examples/graphs/ffmpeg-numpy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, _ = (\n",
    "    ffmpeg\n",
    "    .input(file_path)\n",
    "    .output('pipe:', format='rawvideo', pix_fmt='rgb24')\n",
    "    .run(capture_stdout=True)\n",
    ")\n",
    "video = (\n",
    "    np\n",
    "    .frombuffer(out, np.uint8)\n",
    "    .reshape([-1, height, width, 3])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Single Video as JPEG through pipe\n",
    "![as](https://raw.githubusercontent.com/kkroening/ffmpeg-python/master/examples/graphs/read_frame_as_jpeg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "out, _ = (\n",
    "    ffmpeg\n",
    "    .input(in_filename)\n",
    "    .filter('select', 'gte(n,{})'.format(frame_num))\n",
    "    .output('pipe:', vframes=1, format='image2', vcodec='mjpeg')\n",
    "    .run(capture_stdout=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert sound to raw PCM audio\n",
    "\n",
    "![](https://raw.githubusercontent.com/kkroening/ffmpeg-python/master/examples/graphs/transcribe.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "out, _ = (ffmpeg\n",
    "    .input(in_filename, **input_kwargs)\n",
    "    .output('-', format='s16le', acodec='pcm_s16le', ac=1, ar='16k')\n",
    "    .overwrite_output()\n",
    "    .run(capture_stdout=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble video from sequence of frames\n",
    "![](https://raw.githubusercontent.com/kkroening/ffmpeg-python/master/examples/graphs/glob.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "(\n",
    "    ffmpeg\n",
    "    .input('/path/to/jpegs/*.jpg', pattern_type='glob', framerate=25)\n",
    "    .output('movie.mp4')\n",
    "    .run()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ffmpeg\n",
    "    .input('/path/to/jpegs/*.jpg', pattern_type='glob', framerate=25)\n",
    "    .filter('deflicker', mode='pm', size=10)\n",
    "    .filter('scale', size='hd1080', force_original_aspect_ratio='increase')\n",
    "    .output('movie.mp4', crf=20, preset='slower', movflags='faststart', pix_fmt='yuv420p')\n",
    "    .view(filename='filter_graph')\n",
    "    .run()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio/video pipeline\n",
    "![](https://raw.githubusercontent.com/kkroening/ffmpeg-python/master/examples/graphs/av-pipeline.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in1 = ffmpeg.input('in1.mp4')\n",
    "in2 = ffmpeg.input('in2.mp4')\n",
    "v1 = in1.video.hflip()\n",
    "a1 = in1.audio\n",
    "v2 = in2.video.filter('reverse').filter('hue', s=0)\n",
    "a2 = in2.audio.filter('areverse').filter('aphaser')\n",
    "joined = ffmpeg.concat(v1, a1, v2, a2, v=1, a=1).node\n",
    "v3 = joined[0]\n",
    "a3 = joined[1].filter('volume', 0.8)\n",
    "out = ffmpeg.output(v3, a3, 'out.mp4')\n",
    "out.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mono to stereo with offsets and video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_left = (\n",
    "    ffmpeg\n",
    "    .input('audio-left.wav')\n",
    "    .filter('atrim', start=5)\n",
    "    .filter('asetpts', 'PTS-STARTPTS')\n",
    ")\n",
    "\n",
    "audio_right = (\n",
    "    ffmpeg\n",
    "    .input('audio-right.wav')\n",
    "    .filter('atrim', start=10)\n",
    "    .filter('asetpts', 'PTS-STARTPTS')\n",
    ")\n",
    "\n",
    "input_video = ffmpeg.input('input-video.mp4')\n",
    "\n",
    "(\n",
    "    ffmpeg\n",
    "    .filter((audio_left, audio_right), 'join', inputs=2, channel_layout='stereo')\n",
    "    .output(input_video.video, 'output-video.mp4', shortest=None, vcodec='copy')\n",
    "    .overwrite_output()\n",
    "    .run()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewer in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip3 install ipywidgets\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "from matplotlib import pyplot as plt\n",
    "import ffmpeg\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3840 2160 136\n",
      "{'index': 0, 'codec_name': 'h264', 'codec_long_name': 'H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10', 'profile': 'High', 'codec_type': 'video', 'codec_time_base': '1001/48000', 'codec_tag_string': 'avc1', 'codec_tag': '0x31637661', 'width': 3840, 'height': 2160, 'coded_width': 3840, 'coded_height': 2160, 'has_b_frames': 0, 'sample_aspect_ratio': '1:1', 'display_aspect_ratio': '16:9', 'pix_fmt': 'yuvj420p', 'level': 51, 'color_range': 'pc', 'color_space': 'bt709', 'color_transfer': 'bt709', 'color_primaries': 'bt709', 'chroma_location': 'left', 'refs': 1, 'is_avc': 'true', 'nal_length_size': '4', 'r_frame_rate': '24000/1001', 'avg_frame_rate': '24000/1001', 'time_base': '1/24000', 'start_pts': 0, 'start_time': '0.000000', 'duration_ts': 136136, 'duration': '5.672333', 'bit_rate': '66806828', 'bits_per_raw_sample': '8', 'nb_frames': '136', 'disposition': {'default': 1, 'dub': 0, 'original': 0, 'comment': 0, 'lyrics': 0, 'karaoke': 0, 'forced': 0, 'hearing_impaired': 0, 'visual_impaired': 0, 'clean_effects': 0, 'attached_pic': 0, 'timed_thumbnails': 0}, 'tags': {'creation_time': '1980-09-27T07:00:28.000000Z', 'language': 'eng', 'handler_name': '\\x0bGoPro AVC  ', 'encoder': 'GoPro AVC encoder', 'timecode': '14:03:03:14'}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "probe = ffmpeg.probe(input_file_path)\n",
    "video_info = next((stream for stream in probe['streams'] if stream['codec_type'] == 'video'), None)\n",
    "width = int(video_info['width'])\n",
    "height = int(video_info['height'])\n",
    "num_frames = int(video_info['nb_frames'])\n",
    "\n",
    "print(width, height, num_frames)\n",
    "print(video_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, err = (\n",
    "    ffmpeg\n",
    "    .input(input_file_path)\n",
    "    .output('pipe:', format='rawvideo', pix_fmt='rgb24')\n",
    "    .run(capture_stdout=True)\n",
    ")\n",
    "video = (\n",
    "    np\n",
    "    .frombuffer(out, np.uint8)\n",
    "    .reshape([-1, height, width,3])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620223402d6640a482cefbce3de61b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='frame', max=136), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(frame=(0, num_frames))\n",
    "def show_frame(frame=0):\n",
    "    plt.imshow(video[frame,:,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Stream Editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba073e6a195a42ef95ce9ca0a293b42a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Checkbox(value=True, description='enable_overlay'), Checkbox(value=True, description='en…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def extract_frame(stream, frame_num):\n",
    "    while isinstance(stream, ffmpeg.nodes.OutputStream):\n",
    "        stream = stream.node.incoming_edges[0].upstream_node.stream()\n",
    "    out, _ = (\n",
    "        stream\n",
    "        .filter_('select', 'gte(n,{})'.format(frame_num))\n",
    "        .output('pipe:', format='rawvideo', pix_fmt='rgb24', vframes=1)\n",
    "        .run(capture_stdout=True, capture_stderr=True)\n",
    "    )\n",
    "    return np.frombuffer(out, np.uint8).reshape([height, width, 3])\n",
    "\n",
    "\n",
    "def png_to_np(png_bytes):\n",
    "    buffer = BytesIO(png_bytes)\n",
    "    pil_image = Image.open(buffer)\n",
    "    return np.array(pil_image)\n",
    "    \n",
    "\n",
    "def build_graph(\n",
    "        enable_overlay, flip_overlay, enable_box, box_x, box_y,\n",
    "        thickness, color):\n",
    "\n",
    "    stream = ffmpeg.input(input_file_path)\n",
    "\n",
    "    if enable_overlay:\n",
    "        overlay = ffmpeg.input('overlay.png')\n",
    "        if flip_overlay:\n",
    "            overlay = overlay.hflip()\n",
    "        stream = stream.overlay(overlay)\n",
    "\n",
    "    if enable_box:\n",
    "        stream = stream.drawbox(\n",
    "            box_x, box_y, 120, 120, color=color, t=thickness)\n",
    "\n",
    "    return stream.output('out.mp4')\n",
    "\n",
    "\n",
    "def show_image(ax, stream, frame_num):\n",
    "    try:\n",
    "        image = extract_frame(stream, frame_num)\n",
    "        ax.imshow(image)\n",
    "        ax.axis('off')\n",
    "    except ffmpeg.Error as e:\n",
    "        print(e.stderr.decode())\n",
    "\n",
    "\n",
    "def show_graph(ax, stream, detail):\n",
    "    data = ffmpeg.view(stream, detail=detail, pipe=True)\n",
    "    image = png_to_np(data)\n",
    "    ax.imshow(image, aspect='equal', interpolation='hanning')\n",
    "    ax.set_xlim(0, 1100)\n",
    "    ax.axis('off')\n",
    "\n",
    "\n",
    "@interact(\n",
    "    frame_num=(0, num_frames),\n",
    "    box_x=(0, 200),\n",
    "    box_y=(0, 200),\n",
    "    thickness=(1, 40),\n",
    "    color=['red', 'green', 'magenta', 'blue'],\n",
    ")\n",
    "def f(\n",
    "        enable_overlay=True,\n",
    "        enable_box=True,\n",
    "        flip_overlay=True,\n",
    "        graph_detail=False,\n",
    "        frame_num=0,\n",
    "        box_x=50,\n",
    "        box_y=50,\n",
    "        thickness=5,\n",
    "        color='red'):\n",
    "\n",
    "    stream = build_graph(\n",
    "        enable_overlay,\n",
    "        flip_overlay,\n",
    "        enable_box,\n",
    "        box_x,\n",
    "        box_y,\n",
    "        thickness,\n",
    "        color\n",
    "    )\n",
    "\n",
    "    fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(15,4))\n",
    "    plt.tight_layout()\n",
    "    show_image(ax0, stream, frame_num)\n",
    "    show_graph(ax1, stream, graph_detail)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Streaming\n",
    "\n",
    "https://github.com/kkroening/ffmpeg-python/blob/master/examples/tensorflow_stream.py\n",
    "\n",
    "![](https://raw.githubusercontent.com/kkroening/ffmpeg-python/master/examples/graphs/tensorflow-stream.png)\n",
    "\n",
    "- Decode input video with ffmpeg\n",
    "- Process video with tensorflow using \"deep dream\" example\n",
    "- Encode output video with ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process1 = (\n",
    "    ffmpeg\n",
    "    .input(in_filename)\n",
    "    .output('pipe:', format='rawvideo', pix_fmt='rgb24', vframes=8)\n",
    "    .run_async(pipe_stdout=True)\n",
    ")\n",
    "\n",
    "process2 = (\n",
    "    ffmpeg\n",
    "    .input('pipe:', format='rawvideo', pix_fmt='rgb24', s='{}x{}'.format(width, height))\n",
    "    .output(out_filename, pix_fmt='yuv420p')\n",
    "    .overwrite_output()\n",
    "    .run_async(pipe_stdin=True)\n",
    ")\n",
    "\n",
    "while True:\n",
    "    in_bytes = process1.stdout.read(width * height * 3)\n",
    "    if not in_bytes:\n",
    "        break\n",
    "    in_frame = (\n",
    "        np\n",
    "        .frombuffer(in_bytes, np.uint8)\n",
    "        .reshape([height, width, 3])\n",
    "    )\n",
    "\n",
    "    # See examples/tensorflow_stream.py:\n",
    "    out_frame = deep_dream.process_frame(in_frame)\n",
    "\n",
    "    process2.stdin.write(\n",
    "        out_frame\n",
    "        .astype(np.uint8)\n",
    "        .tobytes()\n",
    "    )\n",
    "\n",
    "process2.stdin.close()\n",
    "process1.wait()\n",
    "process2.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FaceTime webcam input (OS X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ffmpeg\n",
    "    .input('FaceTime', format='avfoundation', pix_fmt='uyvy422', framerate=30)\n",
    "    .output('out.mp4', pix_fmt='yuv420p', vframes=100)\n",
    "    .run()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream from RTSP server to TCP socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packet_size = 4096\n",
    "\n",
    "process = (\n",
    "    ffmpeg\n",
    "    .input('rtsp://%s:8554/default')\n",
    "    .output('-', format='h264')\n",
    "    .run_async(pipe_stdout=True)\n",
    ")\n",
    "\n",
    "while process.poll() is None:\n",
    "    packet = process.stdout.read(packet_size)\n",
    "    try:\n",
    "        tcp_socket.send(packet)\n",
    "    except socket.error:\n",
    "        process.stdout.close()\n",
    "        process.wait()\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyPersonalEnv",
   "language": "python",
   "name": "mypersonalenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
